# 🎯 demo 集合

| 项目     | 描述                                    | 地址             |
| -------- | -------------------------------------- | ---------------- |
| 鱼鱼助手 | [脚本助手](/docs/other/auto/README.md) | https://api-y.cn  |
| 云盘搜索 |            云盘搜索                   | https://yuyu.api-y.cn |




## 云盘搜索
- 使用NET8、Mysql、Elasticsearch、Hangfire、redis、Mediator中介者、RabbitMQ(暂时取消)
-  https://github.com/hu17889/go_spider

# 🚀 云盘搜索项目技术文档

## 📋 项目概述
本项目是一个基于 Go 语言开发的云盘搜索系统，使用 go_spider 框架进行数据爬取，结合 .NET 8 后端服务进行数据处理和验证。系统支持断点续爬功能，确保数据爬取的连续性和完整性。通过浏览器插件实现自动化数据采集和配置管理。

## 🛠️ 技术架构
- 🕷️ 爬虫框架：go_spider (https://github.com/hu17889/go_spider)
- ⚡ 后端服务：.NET8、Mysql、Elasticsearch、Hangfire、redis、Mediator中介者、(RabbitMQ 一致性要求不高 取消掉了 暂时使用redis)
- 💾 数据存储：MySQL + Redis
- 🔧 开发语言：Go + C#
- 🌐 浏览器插件：Chrome Extension

## 🔄 系统流程

### 1️⃣ 浏览器插件功能
1. 🔍 自动采集功能：
   - 📝 自动收集当前页面的 URL
   - 🔑 获取网站 Token
   - 🍪 获取网站 Cookie
   - 🌐 识别网站类型
2. ⚙️ 配置管理：
   - 🔄 代理设置开关
   - 🎯 爬取目标配置
   - ⏰ 定时任务设置
3. 📡 数据同步：
   - 🔄 实时同步到 Go 爬虫服务
   - 📊 状态监控和反馈

### 2️⃣ 数据爬取流程
1. 🕷️ 使用 go_spider 框架爬取目标网站数据 (支持 cookie token 等验证)
2. 📍 支持断点续爬功能：
   - 📝 记录上次爬取位置
   - 💾 保存爬取进度
   - 🔄 支持任务中断恢复
3. 🔍 提取关键信息：数据ID、URL、文章标题
4. 🔐 生成唯一标识 HashID
5. 🧹 数据清洗和格式化

### 3️⃣ 数据存储流程
1. 🔍 根据 HashID 判断数据是新增还是更新
2. 💾 批量写入 MySQL 数据库
3. 🔄 将数据写入 Redis 队列
4. 📡 发送 HTTP 通知到 .NET 8 后端服务

### 4️⃣ 数据验证流程
1. 🔄 .NET 8 后端服务消费 Redis 队列数据
2. ✅ 根据数据类型进行 URL 有效性验证
3. 📊 更新数据状态（有效/无效）
4. ⏰ 定时任务验证 URL 有效性 定时分批同步到Elasticsearch 中


### 5️ 搜索限制
1. 使用中间件对中间件对用户进行

<!-- ![es查询接口](/docs/other/yupan/image.png) -->

## 📊 流程图
![alt text](mermaid-2.png)
```mermaid
graph LR
    A[🌐 浏览器插件] --> B[📡 发送配置数据]
    B --> C[⏰ Cron定时任务]
    C --> D[🚀 开始爬取]
    D --> E[📝 检查断点记录]
    E --> F{❓ 是否存在断点}
    F -->|✅ 是| G[🔄 从断点继续爬取]
    F -->|❌ 否| H[🕷️ go_spider爬虫]
    G --> I[🔍 数据提取]
    H --> I
    I --> J[🔐 生成HashID]
    J --> K{📊 数据判断}
    K -->|➕ 新增| L[💾 MySQL写入]
    K -->|🔄 更新| M[📝 MySQL更新]
    L --> N[🔄 Redis写入]
    M --> N
    N --> O[📡 通知.NET服务]
    O --> P[🔄 消费Redis数据]
    P --> Q[✅ URL验证]
    Q --> R{🔍 URL是否有效}
    R -->|✅ 有效| S[📊 更新状态]
    R -->|❌ 无效| T[❌ 标记无效]
    S --> U[⏰ 定时验证]
    T --> U
    U --> V{⏰ 是否到达验证时间}
    V -->|✅ 是| Q
    V -->|❌ 否| W[⏳ 等待下次验证]
    W --> V
    I --> X[💾 保存断点记录]
    X --> Y[⏰ 定时保存进度]
```

## 🔑 关键功能说明

### 1️⃣ 浏览器插件功能
- 🌐 自动采集网站数据
- 🔑 管理认证信息
- ⚙️ 配置爬取参数
- 📡 实时数据同步

### 2️⃣ 定时任务
- ⏰ 使用 Cron 表达式配置爬虫执行时间
- 🔄 支持灵活的任务调度策略
- 📅 可配置多个时间点执行

### 3️⃣ 断点续爬功能
- 🔄 支持任务中断恢复
- 📝 记录爬取进度和位置
- 💾 定时保存断点信息
- ⚡ 支持多任务并行爬取
- 🔒 确保数据爬取的连续性

### 4️⃣ HashID 生成
- 🔐 基于数据ID、URL、文章标题生成唯一标识
- 🔑 使用加密算法生成短字符串
- 📊 用于判断数据是新增还是更新
- 🔒 保证数据的唯一性和可追踪性

### 5️⃣ 数据存储
- 💾 MySQL：存储完整数据
- 🔄 Redis：存储待处理数据队列

### 6️⃣ URL 验证
- ✅ 实时验证：数据入库时进行验证
- ⏰ 定时验证：每天定时检查 URL 有效性

## 🚀 部署要求
1. 🔧 Go 环境配置
2. ⚡ .NET 8 运行环境
3. 💾 MySQL 数据库
4. 🔄 Redis 服务
5. 🌐 Chrome 浏览器